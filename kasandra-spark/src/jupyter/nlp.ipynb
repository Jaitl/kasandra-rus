{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msparkHome\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"/data/spark/spark-1.6.1-bin-hadoop2.6\"\u001b[0m\n",
       "\u001b[36msparkAssembly\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"/data/spark/spark-1.6.1-bin-hadoop2.6/lib/spark-assembly-1.6.1-hadoop2.6.0.jar\"\u001b[0m\n",
       "\u001b[36msparkMaster\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"spark://localhost:7077\"\u001b[0m\n",
       "\u001b[36msparkVersion\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"1.6.1\"\u001b[0m\n",
       "\u001b[36mscalaVersion\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"2.11.8\"\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val sparkHome = \"/data/spark/spark-1.6.1-bin-hadoop2.6\"\n",
    "val sparkAssembly = s\"$sparkHome/lib/spark-assembly-1.6.1-hadoop2.6.0.jar\"\n",
    "val sparkMaster = \"spark://localhost:7077\"\n",
    "val sparkVersion = \"1.6.1\"\n",
    "val scalaVersion = scala.util.Properties.versionNumberString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 new artifact(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146 new artifacts in macro\n",
      "146 new artifacts in runtime\n",
      "146 new artifacts in compile\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\n",
    "    \"com.github.alexarchambault.ammonium\" % \"spark_1.6.1_2.11.8\" % \"0.4.0-M6-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "16/08/10 19:04:01 INFO Spark$SparkContext: Running Spark version 1.6.1\n",
      "16/08/10 19:04:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/08/10 19:04:01 INFO SecurityManager: Changing view acls to: igor\n",
      "16/08/10 19:04:01 INFO SecurityManager: Changing modify acls to: igor\n",
      "16/08/10 19:04:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(igor); users with modify permissions: Set(igor)\n",
      "16/08/10 19:04:02 INFO Utils: Successfully started service 'sparkDriver' on port 54306.\n",
      "16/08/10 19:04:02 INFO Slf4jLogger: Slf4jLogger started\n",
      "16/08/10 19:04:02 INFO Remoting: Starting remoting\n",
      "16/08/10 19:04:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.129.31:54307]\n",
      "16/08/10 19:04:02 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 54307.\n",
      "16/08/10 19:04:02 INFO SparkEnv: Registering MapOutputTracker\n",
      "16/08/10 19:04:02 INFO SparkEnv: Registering BlockManagerMaster\n",
      "16/08/10 19:04:02 INFO DiskBlockManager: Created local directory at /private/var/folders/ph/glk6y4gx26j42jtpv890dyzm0000gn/T/blockmgr-a7e70f95-36b7-4932-91fd-f88b08ebc925\n",
      "16/08/10 19:04:02 INFO MemoryStore: MemoryStore started with capacity 1482.0 MB\n",
      "16/08/10 19:04:03 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "16/08/10 19:04:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "16/08/10 19:04:03 INFO SparkUI: Started SparkUI at http://192.168.129.31:4040\n",
      "16/08/10 19:04:03 INFO HttpFileServer: HTTP File server directory is /private/var/folders/ph/glk6y4gx26j42jtpv890dyzm0000gn/T/spark-9ea611f8-b0eb-4e85-abc6-f248f2c86792/httpd-5d1f3baa-cfc0-4dc6-aca8-cb8d76422390\n",
      "16/08/10 19:04:03 INFO HttpServer: Starting HTTP Server\n",
      "16/08/10 19:04:03 INFO Utils: Successfully started service 'HTTP file server' on port 54308.\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-xml_2.11-1.0.4.jar at http://192.168.129.31:54308/jars/scala-xml_2.11-1.0.4.jar with timestamp 1470845043583\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-compiler-2.11.8.jar at http://192.168.129.31:54308/jars/scala-compiler-2.11.8.jar with timestamp 1470845043731\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/kernel-api_2.11-0.3.0-M5.jar at http://192.168.129.31:54308/jars/kernel-api_2.11-0.3.0-M5.jar with timestamp 1470845043732\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/sourcecode_2.11-0.1.1.jar at http://192.168.129.31:54308/jars/sourcecode_2.11-0.1.1.jar with timestamp 1470845043733\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/interpreter-api_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/interpreter-api_2.11.8-0.4.0-M6-1.jar with timestamp 1470845043735\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/pprint_2.11-0.3.9.jar at http://192.168.129.31:54308/jars/pprint_2.11-0.3.9.jar with timestamp 1470845043737\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-reflect-2.11.8.jar at http://192.168.129.31:54308/jars/scala-reflect-2.11.8.jar with timestamp 1470845043767\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/tprint_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/tprint_2.11.8-0.4.0-M6-1.jar with timestamp 1470845043840\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-api_2.11.8-0.3.0-M3.jar at http://192.168.129.31:54308/jars/scala-api_2.11.8-0.3.0-M3.jar with timestamp 1470845043841\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/derive_2.11-0.3.9.jar at http://192.168.129.31:54308/jars/derive_2.11-0.3.9.jar with timestamp 1470845043842\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-library-2.11.8.jar at http://192.168.129.31:54308/jars/scala-library-2.11.8.jar with timestamp 1470845043898\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/.jupyter-scala/bootstrap/scala-parser-combinators_2.11-1.0.4.jar at http://192.168.129.31:54308/jars/scala-parser-combinators_2.11-1.0.4.jar with timestamp 1470845043901\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Users/igor/Library/Jupyter/kernels/scala211/launcher.jar at http://192.168.129.31:54308/jars/launcher.jar with timestamp 1470845043903\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/cldrdata.jar at http://192.168.129.31:54308/jars/cldrdata.jar with timestamp 1470845043926\n",
      "16/08/10 19:04:03 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/dnsns.jar at http://192.168.129.31:54308/jars/dnsns.jar with timestamp 1470845043927\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/jaccess.jar at http://192.168.129.31:54308/jars/jaccess.jar with timestamp 1470845044000\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/jfxrt.jar at http://192.168.129.31:54308/jars/jfxrt.jar with timestamp 1470845044116\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/localedata.jar at http://192.168.129.31:54308/jars/localedata.jar with timestamp 1470845044122\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/nashorn.jar at http://192.168.129.31:54308/jars/nashorn.jar with timestamp 1470845044129\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/sunec.jar at http://192.168.129.31:54308/jars/sunec.jar with timestamp 1470845044130\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar at http://192.168.129.31:54308/jars/sunjce_provider.jar with timestamp 1470845044133\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar at http://192.168.129.31:54308/jars/sunpkcs11.jar with timestamp 1470845044135\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Library/Java/JavaVirtualMachines/jdk1.8.0_65.jdk/Contents/Home/jre/lib/ext/zipfs.jar at http://192.168.129.31:54308/jars/zipfs.jar with timestamp 1470845044222\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/AppleScriptEngine.jar at http://192.168.129.31:54308/jars/AppleScriptEngine.jar with timestamp 1470845044223\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/dns_sd.jar at http://192.168.129.31:54308/jars/dns_sd.jar with timestamp 1470845044224\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/j3daudio.jar at http://192.168.129.31:54308/jars/j3daudio.jar with timestamp 1470845044229\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/j3dcore.jar at http://192.168.129.31:54308/jars/j3dcore.jar with timestamp 1470845044234\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/j3dutils.jar at http://192.168.129.31:54308/jars/j3dutils.jar with timestamp 1470845044237\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/jai_codec.jar at http://192.168.129.31:54308/jars/jai_codec.jar with timestamp 1470845044333\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/jai_core.jar at http://192.168.129.31:54308/jars/jai_core.jar with timestamp 1470845044343\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/mlibwrapper_jai.jar at http://192.168.129.31:54308/jars/mlibwrapper_jai.jar with timestamp 1470845044344\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/MRJToolkit.jar at http://192.168.129.31:54308/jars/MRJToolkit.jar with timestamp 1470845044345\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/System/Library/Java/Extensions/vecmath.jar at http://192.168.129.31:54308/jars/vecmath.jar with timestamp 1470845044348\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.4/scala-parser-combinators_2.11-1.0.4.jar at http://192.168.129.31:54308/jars/scala-parser-combinators_2.11-1.0.4.jar with timestamp 1470845044359\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.0.4/scala-xml_2.11-1.0.4.jar at http://192.168.129.31:54308/jars/scala-xml_2.11-1.0.4.jar with timestamp 1470845044443\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/ammonium/tprint_2.11.8/0.4.0-M6-1/tprint_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/tprint_2.11.8-0.4.0-M6-1.jar with timestamp 1470845044444\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/ammonium/interpreter-api_2.11.8/0.4.0-M6-1/interpreter-api_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/interpreter-api_2.11.8-0.4.0-M6-1.jar with timestamp 1470845044445\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/jupyter/kernel-api_2.11/0.3.0-M5/kernel-api_2.11-0.3.0-M5.jar at http://192.168.129.31:54308/jars/kernel-api_2.11-0.3.0-M5.jar with timestamp 1470845044446\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/jupyter/scala-api_2.11.8/0.3.0-M3/scala-api_2.11.8-0.3.0-M3.jar at http://192.168.129.31:54308/jars/scala-api_2.11.8-0.3.0-M3.jar with timestamp 1470845044546\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.11.8/scala-compiler-2.11.8.jar at http://192.168.129.31:54308/jars/scala-compiler-2.11.8.jar with timestamp 1470845044672\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar at http://192.168.129.31:54308/jars/scala-reflect-2.11.8.jar with timestamp 1470845044709\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.11/0.3.9/pprint_2.11-0.3.9.jar at http://192.168.129.31:54308/jars/pprint_2.11-0.3.9.jar with timestamp 1470845044711\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar at http://192.168.129.31:54308/jars/scala-library-2.11.8.jar with timestamp 1470845044743\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.11/0.1.1/sourcecode_2.11-0.1.1.jar at http://192.168.129.31:54308/jars/sourcecode_2.11-0.1.1.jar with timestamp 1470845044744\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/derive_2.11/0.3.9/derive_2.11-0.3.9.jar at http://192.168.129.31:54308/jars/derive_2.11-0.3.9.jar with timestamp 1470845044745\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar at http://192.168.129.31:54308/jars/jetty-util-8.1.14.v20131031.jar with timestamp 1470845044747\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/ammonium/shell-api_2.11.8/0.4.0-M6-1/shell-api_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/shell-api_2.11.8-0.4.0-M6-1.jar with timestamp 1470845044832\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar at http://192.168.129.31:54308/jars/jetty-server-8.1.14.v20131031.jar with timestamp 1470845044834\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar at http://192.168.129.31:54308/jars/jetty-http-8.1.14.v20131031.jar with timestamp 1470845044835\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/ammonium/spark_1.6.1_2.11.8/0.4.0-M6-1/spark_1.6.1_2.11.8-0.4.0-M6-1.jar at http://192.168.129.31:54308/jars/spark_1.6.1_2.11.8-0.4.0-M6-1.jar with timestamp 1470845044837\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar at http://192.168.129.31:54308/jars/jetty-io-8.1.14.v20131031.jar with timestamp 1470845044942\n",
      "16/08/10 19:04:04 INFO Spark$SparkContext: Added JAR file:/Users/igor/.coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar at http://192.168.129.31:54308/jars/jetty-continuation-8.1.14.v20131031.jar with timestamp 1470845044943\n",
      "16/08/10 19:04:05 INFO Executor: Starting executor ID driver on host localhost\n",
      "16/08/10 19:04:05 INFO Executor: Using REPL class URI: http://192.168.129.31:54305\n",
      "16/08/10 19:04:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54309.\n",
      "16/08/10 19:04:05 INFO NettyBlockTransferService: Server created on 54309\n",
      "16/08/10 19:04:05 INFO BlockManagerMaster: Trying to register BlockManager\n",
      "16/08/10 19:04:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54309 with 1482.0 MB RAM, BlockManagerId(driver, localhost, 54309)\n",
      "16/08/10 19:04:05 INFO BlockManagerMaster: Registered BlockManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mSpark\u001b[0m: \u001b[32mammonite\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mSpark\u001b[0m = Spark\n",
       "\u001b[36mconf\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mSparkConf\u001b[0m = org.apache.spark.SparkConf@3826c68e\n",
       "\u001b[36msc\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mSparkContext\u001b[0m = SparkContext"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@transient val Spark = new ammonite.spark.Spark\n",
    "\n",
    "@transient val conf =\n",
    "  Spark\n",
    "    .sparkConf\n",
    "    .setAppName(\"Content Similarity\")\n",
    "    .set(\"spark.home\", sparkHome)\n",
    "\n",
    "@transient val sc = Spark.sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36maccum\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mAccumulator\u001b[0m[\u001b[32mInt\u001b[0m] = 55\n",
       "\u001b[36mres3_2\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m55\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val accum = sc.accumulator(0)\n",
    "sc.parallelize(1 to 10).foreach(x => accum += x)\n",
    "accum.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
