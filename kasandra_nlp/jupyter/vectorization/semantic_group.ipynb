{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from pymystem3 import Mystem\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('/data/gensim/news_0_300_2.bin.gz', binary=True)\n",
    "word_vectors.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystem_part = {\n",
    "    'A': 'ADJ', # прилагательное\n",
    "    'ADV': 'ADV', # наречие\n",
    "    'ADVPRO': 'ADV', # местоименное наречие\n",
    "    'ANUM': 'ADJ', # числительное-прилагательное\n",
    "    'APRO': 'DET', # местоимение-прилагательное\n",
    "    'COM': 'ADJ', # часть композита - сложного слова\n",
    "    'CONJ': 'SCONJ', # союз\n",
    "    'INTJ': 'INTJ',\t# междометие\n",
    "    'NUM': 'NUM', # числительное\n",
    "    'PART': 'PART',\t# частица\n",
    "    'PR': 'ADP', # предлог\n",
    "    'S': 'NOUN', # существительное\n",
    "    'SPRO': 'PRON',\n",
    "    'V': 'VERB', # глагол\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemm(word):\n",
    "    a = mystem.analyze(word)\n",
    "    \n",
    "    if len(a) == 0:\n",
    "        return word\n",
    "    \n",
    "    analysis = a[0]['analysis']\n",
    "    \n",
    "    if len(analysis) == 0:\n",
    "        return word\n",
    "    \n",
    "    gr = analysis[0]\n",
    "    parts = gr['gr'].split(\"=\")\n",
    "    \n",
    "    if len(parts) == 0:\n",
    "        return word\n",
    "    \n",
    "    parts2 = parts[0].split(\",\")\n",
    "        \n",
    "    if len(parts2) == 0:\n",
    "        return word\n",
    "    \n",
    "    part = parts2[0]\n",
    "        \n",
    "    if part in mystem_part:\n",
    "        return \"%s_%s\" % (analysis[0]['lex'], mystem_part[part])\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similar(word, lemming=True):\n",
    "    try:\n",
    "        if lemming:\n",
    "            w = lemm(word)\n",
    "        else:\n",
    "            w = word\n",
    "        sim = word_vectors.most_similar(positive=[w])\n",
    "        return list(map(lambda x: x[0], sim))\n",
    "    except Exception as e:\n",
    "        return [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractSemanticGroup(seq):\n",
    "    token_seq = map(lambda x: map(lambda y: lemm(y), x.split(\" \")), seq)\n",
    "    res_seq = []\n",
    "    sem_groups = {}\n",
    "    for words in token_seq:\n",
    "        res_tokens = []\n",
    "        for token in words:\n",
    "            if token not in sem_groups:\n",
    "                sims = similar(token, False)\n",
    "                sem_groups[token] = token\n",
    "                res_tokens.append(token)\n",
    "                for sim in sims:\n",
    "                   sem_groups[sim] = token\n",
    "            else:\n",
    "                res_tokens.append(sem_groups[token])\n",
    "        res_seq.append(res_tokens)\n",
    "    result = map(lambda x: \" \".join(map(lambda y: y.split(\"_\")[0], x)), res_seq)\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unic_count(seq):\n",
    "    total = []\n",
    "    for s in seq:\n",
    "        total.extend(s.split(\" \"))\n",
    "    return len(set(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = [\n",
    "    \"свидетель редкий природный явление становиться житель москва первый день февраль рано утро многий разбудить раскат гром настоящий зимний гроза сопровождаться молния порыв ветер метр секунда ледяной дождь новый месяц\",\n",
    "    \"обвинять государственный измена домохозяйка вязьма светлана давыдов освобождать подписка невыезд страница фейсбук сообщать адвокат женщина иван павлов ходатайство защита изменение мера пресечение удовлетворять следователь взять подписка невыезд мать смочь вернуться ребенок сообщать защитник давыдова судя адвокат новость\",\n",
    "    \"пока ребенок школа выращивать фасоль выращивать грудь говорить героиня популярный сериал глупо звучать грудь выращивать подращивать немного итак нужно делать качать мышца грудь поддерживать грудной мышца любой мышца тело подкачивать укреплять интернет смочь узнавать упражнение тренажер дом коврик помогать прорабатывать мышца грудь мышца окрепнуть подрастать грудь выглядеть пить молоко бабушка советовать капуста грудь расти\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['свидетель редкий природный явление становиться житель москва первый день февраль рано утро многий разбудить раскат гром настоящий зимний гроза сопровождаться молния порыв порыв метр секунда ледяной гроза новый день', 'обвинять государственный измена домохозяйка вязьма светлана давыдов освобождать подписка подписка страница страница сообщать адвокат женщина иван павлов ходатайство защита изменение мера пресечение удовлетворять следователь взять подписка подписка мать смочь вернуться ребенок сообщать защитник давыдов судя адвокат новость', 'пока ребенок школа выращивать фасоль выращивать грудь говорить героиня популярный сериал глупо звучать грудь выращивать подращивать немного итак нужно делать качать мышца грудь поддерживать грудной мышца любой мышца тело подкачивать укреплять интернет нужно узнавать упражнение тренажер дом коврик помогать прорабатывать мышца грудь мышца окрепнуть подрастать грудь выглядеть пить молоко мать советовать капуста грудь расти']\n",
      "time: 1.4393730163574219 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res = extractSemanticGroup(news)\n",
    "print(res)\n",
    "print(\"time: %s s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_count(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_count(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "class News:\n",
    "    def __init__(self, id, date, title, content, url, siteType):\n",
    "        self.id = id\n",
    "        self.date = date\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.url = url\n",
    "        self.siteType = siteType\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str):\n",
    "        json_dict = json.loads(json_str)\n",
    "        return cls(**json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('/data/kasandra/year/10k.test.normalized.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        news.append(News.from_json(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = list(map(lambda x: x.content, news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66845"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_count(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 696.5620369911194 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sem_content = extractSemanticGroup(content)\n",
    "print(\"time: %s s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36093"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_count(sem_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2005.195344209671 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sem_content = extractSemanticGroup(content, 5)\n",
    "print(\"time: %s s\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36093"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unic_count(sem_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
