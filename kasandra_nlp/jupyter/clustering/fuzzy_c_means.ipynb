{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import skfuzzy as fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class News:\n",
    "    def __init__(self, id, date, title, content, url, siteType):\n",
    "        self.id = id\n",
    "        self.date = date\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.url = url\n",
    "        self.siteType = siteType\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str):\n",
    "        json_dict = json.loads(json_str)\n",
    "        return cls(**json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('/data/kasandra/year/all.normalized.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        news.append(News.from_json(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 47479434\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for n in news:\n",
    "    words.extend(n.content.split())\n",
    "counts = Counter(words)\n",
    "one_time = [k for k, v in dict(counts).items() if v == 1]\n",
    "print(\"total words: %s\" % (len(words) - len(one_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(one_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_news(n,l):\n",
    "    return list(map(assign_label_to_news, zip(n, l)))\n",
    "\n",
    "def assign_label_to_news(tuplezz):\n",
    "    (nws, lbl) = tuplezz\n",
    "    nws.label = lbl.item()\n",
    "    return nws\n",
    "\n",
    "def filter_words(text):\n",
    "    words_list = text.split()\n",
    "    newWords = [x for x in words_list if len(x) > 3]\n",
    "    return \" \".join(newWords)\n",
    "\n",
    "def print_clusters(cluster_news, clustre_labels):\n",
    "    newsLabels = zip_news(cluster_news, clustre_labels)\n",
    "    newsLabels = sorted(newsLabels, key=lambda n: n.label)\n",
    "    for label, group in groupby(newsLabels, lambda n: n.label):\n",
    "        groupList = list(group)\n",
    "        print(\"Cluster: %s, count news: %s, titles:\" % (label, len(groupList)))\n",
    "        for gr in groupList:\n",
    "            print(\"\\t\" + gr.title)\n",
    "            \n",
    "def print_topics(components, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(components):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count mart news: 2684\n",
      "vocabulary size: 36964\n"
     ]
    }
   ],
   "source": [
    "mart_start = 1425157200000\n",
    "mart_end = 1427835600000\n",
    "\n",
    "mart_news = list(filter(lambda x: x.date > mart_start and x.date < mart_end, news))\n",
    "mart_content = [filter_words(x.content) for x in mart_news]\n",
    "print(\"count mart news: %s\" % len(mart_content))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, tokenizer=lambda text: text.split(\" \"), stop_words=stopwords) # , ngram_range=(1, 3)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(mart_content)\n",
    "print(\"vocabulary size: %s\" % len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncenters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(tfidf_matrix, ncenters, 2, error=0.5, maxiter=100, init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
