{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение алгоритмов кластеризации по метрикам качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class News:\n",
    "    def __init__(self, id, date, title, content, url, siteType):\n",
    "        self.id = id\n",
    "        self.date = date\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.url = url\n",
    "        self.siteType = siteType\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str):\n",
    "        json_dict = json.loads(json_str)\n",
    "        return cls(**json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('/data/10k.test.normalized.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        news.append(News.from_json(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 2717122\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for n in news:\n",
    "    words.extend(n.content.split())\n",
    "counts = Counter(words)\n",
    "one_time = [k for k, v in dict(counts).items() if v == 1]\n",
    "print(\"total words: %s\" % (len(words) - len(one_time)))\n",
    "\n",
    "news_content = [x.content for x in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(one_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка размеченной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_map = {} # (id, label)\n",
    "with open('/data/mark_news.csv', encoding=\"utf8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    for row in spamreader:\n",
    "        marked_map[row[0]] = int(row[3])\n",
    "\n",
    "marked_news = []\n",
    "for n in news:\n",
    "    label = marked_map[n.id]\n",
    "    marked_news.append((n.id, label))\n",
    "    \n",
    "marked_labels = [label for n_id, label in marked_news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked_map['170bf9b9-d62d-437e-a75a-cac7b7c9f282']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_news(n,l):\n",
    "    return list(map(assign_label_to_news, zip(n, l)))\n",
    "\n",
    "def assign_label_to_news(tuplezz):\n",
    "    (nws, lbl) = tuplezz\n",
    "    nws.label = lbl.item()\n",
    "    return nws\n",
    "\n",
    "def filter_words(text):\n",
    "    words_list = text.split()\n",
    "    newWords = [x for x in words_list if len(x) > 3]\n",
    "    return \" \".join(newWords)\n",
    "\n",
    "def print_clusters(cluster_news, clustre_labels):\n",
    "    newsLabels = zip_news(cluster_news, clustre_labels)\n",
    "    newsLabels = sorted(newsLabels, key=lambda n: n.label)\n",
    "    for label, group in groupby(newsLabels, lambda n: n.label):\n",
    "        groupList = list(group)\n",
    "        print(\"Cluster: %s, count news: %s, titles:\" % (label, len(groupList)))\n",
    "        for gr in groupList:\n",
    "            print(\"\\t\" + gr.title)\n",
    "            \n",
    "def print_topics(components, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(components):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(content):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, tokenizer=lambda text: text.split(\" \"), stop_words=stopwords) # , ngram_range=(1, 3)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(content)\n",
    "    print(\"vocabulary size: %s\" % len(tfidf_vectorizer.vocabulary_))\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(content):\n",
    "    tf_vectorizer = TfidfVectorizer(use_idf=False, tokenizer=lambda text: text.split(\" \"), stop_words=stopwords) # , ngram_range=(1, 3)\n",
    "    tf_matrix = tfidf_vectorizer.fit_transform(content)\n",
    "    print(\"vocabulary size: %s\" % len(tf_vectorizer.vocabulary_))\n",
    "    return tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семантический анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda(content, n, max_iter):\n",
    "    tf = CountVectorizer(stop_words=stopwords).fit_transform(content)\n",
    "    lda = LatentDirichletAllocation(n_topics=n, max_iter=max_iter, learning_method='online', learning_offset=50.)\n",
    "    lda_matrix = lda.fit_transform(tf)\n",
    "    normalizer = Normalizer()\n",
    "    norm_matrix = normalizer.fit_transform(lda_matrix)\n",
    "    return norm_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lsa(matrix, n, max_inter):\n",
    "    lsa = TruncatedSVD(n_components=n, n_iter=max_inter)\n",
    "    lsa_matrix = lsa.fit_transform(matrix)\n",
    "    return lsa_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(matrix, marked_labels, clustered_labels):\n",
    "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(marked_labels, clustered_labels))\n",
    "    print(\"Completeness: %0.3f\" % metrics.completeness_score(marked_labels, clustered_labels))\n",
    "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(marked_labels, clustered_labels))\n",
    "    print(\"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(marked_labels, clustered_labels))\n",
    "    print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(matrix, clustered_labels, sample_size=1000))\n",
    "    print(\"Cluster count: %s\" % len(set(clustered_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter = 100 # 100\n",
    "n_components = 10000\n",
    "n_clusters = 130 # Количество кластеров\n",
    "min_samples = 4\n",
    "eps = 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 15558\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tf_idf(news_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 15558\n"
     ]
    }
   ],
   "source": [
    "vectorization = {\n",
    "    \"tf-idf\": tfidf_matrix,\n",
    "    \"tf\": tf_idf(news_content),\n",
    "    \"lda\": lda(news_content, n_components, max_iter),\n",
    "    \"lsa\": lsa(tfidf_matrix, n_components, max_iter)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clasterization = {\n",
    "    \"kmeans\": KMeans(n_clusters=n_clusters),\n",
    "    \"miniBatchKMeanss\": MiniBatchKMeans(n_clusters=n_clusters, max_iter=max_iter),\n",
    "    \"dbscan\": DBSCAN(eps=eps, min_samples=min_samples),\n",
    "    \"birch\": Birch(n_clusters=n_clusters),\n",
    "    \"affinityPropagation\": AffinityPropagation()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans tf-idf\n",
      "Homogeneity: 0.859\n",
      "Completeness: 0.690\n",
      "V-measure: 0.766\n",
      "Adjusted Rand-Index: 0.251\n",
      "Silhouette Coefficient: 0.070\n",
      "Cluster count: 130\n",
      "kmeans tf-idf: 8.435837030410767 second\n",
      "----\n",
      "kmeans tf\n",
      "Homogeneity: 0.853\n",
      "Completeness: 0.685\n",
      "V-measure: 0.760\n",
      "Adjusted Rand-Index: 0.246\n",
      "Silhouette Coefficient: 0.064\n",
      "Cluster count: 130\n",
      "kmeans tf: 8.243932008743286 second\n",
      "----\n",
      "kmeans lda\n",
      "Homogeneity: 0.589\n",
      "Completeness: 0.486\n",
      "V-measure: 0.532\n",
      "Adjusted Rand-Index: 0.003\n",
      "Silhouette Coefficient: 0.535\n",
      "Cluster count: 130\n",
      "kmeans lda: 0.7911496162414551 second\n",
      "----\n",
      "kmeans lsa\n",
      "Homogeneity: 0.853\n",
      "Completeness: 0.682\n",
      "V-measure: 0.757\n",
      "Adjusted Rand-Index: 0.216\n",
      "Silhouette Coefficient: 0.285\n",
      "Cluster count: 130\n",
      "kmeans lsa: 0.8746170997619629 second\n",
      "----\n",
      "miniBatchKMeanss tf-idf\n",
      "Homogeneity: 0.577\n",
      "Completeness: 0.648\n",
      "V-measure: 0.610\n",
      "Adjusted Rand-Index: 0.053\n",
      "Silhouette Coefficient: -0.016\n",
      "Cluster count: 125\n",
      "miniBatchKMeanss tf-idf: 1.9130744934082031 second\n",
      "----\n",
      "miniBatchKMeanss tf\n",
      "Homogeneity: 0.567\n",
      "Completeness: 0.647\n",
      "V-measure: 0.604\n",
      "Adjusted Rand-Index: 0.056\n",
      "Silhouette Coefficient: -0.000\n",
      "Cluster count: 123\n",
      "miniBatchKMeanss tf: 1.9249560832977295 second\n",
      "----\n",
      "miniBatchKMeanss lda\n",
      "Homogeneity: 0.611\n",
      "Completeness: 0.493\n",
      "V-measure: 0.546\n",
      "Adjusted Rand-Index: 0.001\n",
      "Silhouette Coefficient: 0.551\n",
      "Cluster count: 130\n",
      "miniBatchKMeanss lda: 0.6470127105712891 second\n",
      "----\n",
      "miniBatchKMeanss lsa\n",
      "Homogeneity: 0.834\n",
      "Completeness: 0.678\n",
      "V-measure: 0.748\n",
      "Adjusted Rand-Index: 0.197\n",
      "Silhouette Coefficient: 0.245\n",
      "Cluster count: 129\n",
      "miniBatchKMeanss lsa: 0.6381025314331055 second\n",
      "----\n",
      "dbscan tf-idf\n",
      "Homogeneity: 0.220\n",
      "Completeness: 0.658\n",
      "V-measure: 0.330\n",
      "Adjusted Rand-Index: 0.008\n",
      "Silhouette Coefficient: 0.019\n",
      "Cluster count: 19\n",
      "dbscan tf-idf: 0.07653927803039551 second\n",
      "----\n",
      "dbscan tf\n",
      "Homogeneity: 0.220\n",
      "Completeness: 0.658\n",
      "V-measure: 0.330\n",
      "Adjusted Rand-Index: 0.008\n",
      "Silhouette Coefficient: 0.019\n",
      "Cluster count: 19\n",
      "dbscan tf: 0.07439422607421875 second\n",
      "----\n",
      "dbscan lda\n",
      "Homogeneity: -0.000\n",
      "Completeness: 1.000\n",
      "V-measure: -0.000\n",
      "Adjusted Rand-Index: 0.000\n",
      "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
      "dbscan lsa\n",
      "Homogeneity: -0.000\n",
      "Completeness: 1.000\n",
      "V-measure: -0.000\n",
      "Adjusted Rand-Index: 0.000\n",
      "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
      "birch tf-idf\n",
      "Homogeneity: 0.873\n",
      "Completeness: 0.699\n",
      "V-measure: 0.776\n",
      "Adjusted Rand-Index: 0.294\n",
      "Silhouette Coefficient: 0.074\n",
      "Cluster count: 130\n",
      "birch tf-idf: 2.8103291988372803 second\n",
      "----\n",
      "birch tf\n",
      "Homogeneity: 0.873\n",
      "Completeness: 0.699\n",
      "V-measure: 0.776\n",
      "Adjusted Rand-Index: 0.294\n",
      "Silhouette Coefficient: 0.074\n",
      "Cluster count: 130\n",
      "birch tf: 2.8294405937194824 second\n",
      "----\n",
      "birch lda\n",
      "Homogeneity: -0.000\n",
      "Completeness: 1.000\n",
      "V-measure: -0.000\n",
      "Adjusted Rand-Index: 0.000\n",
      "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n",
      "birch lsa\n",
      "Homogeneity: 0.687\n",
      "Completeness: 0.689\n",
      "V-measure: 0.688\n",
      "Adjusted Rand-Index: 0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cluster/birch.py:602: UserWarning: Number of subclusters found (1) by Birch is less than (130). Decrease the threshold.\n",
      "  % (len(centroids), self.n_clusters))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/cluster/birch.py:602: UserWarning: Number of subclusters found (96) by Birch is less than (130). Decrease the threshold.\n",
      "  % (len(centroids), self.n_clusters))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.214\n",
      "Cluster count: 96\n",
      "birch lsa: 0.2521991729736328 second\n",
      "----\n",
      "affinityPropagation tf-idf\n",
      "Homogeneity: 0.816\n",
      "Completeness: 0.713\n",
      "V-measure: 0.761\n",
      "Adjusted Rand-Index: 0.350\n",
      "Silhouette Coefficient: 0.064\n",
      "Cluster count: 86\n",
      "affinityPropagation tf-idf: 0.8325362205505371 second\n",
      "----\n",
      "affinityPropagation tf\n",
      "Homogeneity: 0.816\n",
      "Completeness: 0.713\n",
      "V-measure: 0.761\n",
      "Adjusted Rand-Index: 0.350\n",
      "Silhouette Coefficient: 0.064\n",
      "Cluster count: 86\n",
      "affinityPropagation tf: 0.8357975482940674 second\n",
      "----\n",
      "affinityPropagation lda\n",
      "Homogeneity: 0.399\n",
      "Completeness: 0.454\n",
      "V-measure: 0.424\n",
      "Adjusted Rand-Index: 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:204: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.312\n",
      "Cluster count: 128\n",
      "affinityPropagation lda: 0.9901378154754639 second\n",
      "----\n",
      "affinityPropagation lsa\n",
      "Homogeneity: 0.754\n",
      "Completeness: 0.693\n",
      "V-measure: 0.722\n",
      "Adjusted Rand-Index: 0.228\n",
      "Silhouette Coefficient: 0.265\n",
      "Cluster count: 81\n",
      "affinityPropagation lsa: 0.40547633171081543 second\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for cl_name, cl_alg in clasterization.items():\n",
    "    for vec_name, vec_matrix in vectorization.items():\n",
    "        try:\n",
    "            print(\"%s %s\" % (cl_name, vec_name))\n",
    "            start_time = time.time()\n",
    "            result_matrix = cl_alg.fit(vec_matrix)\n",
    "            labels = result_matrix.labels_\n",
    "            score(vec_matrix, marked_labels, labels)\n",
    "            print(\"%s %s: %s second\" % (cl_name, vec_name, time.time() - start_time))\n",
    "            print(\"----\")\n",
    "        except Exception as ex:\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.170\n",
      "Completeness: 0.773\n",
      "V-measure: 0.279\n",
      "Adjusted Rand-Index: 0.054\n",
      "Silhouette Coefficient: 0.803\n",
      "Cluster count: 9\n",
      "lda lda: 12.823763608932495 second\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lda_matrix = lda(news_content, n_clusters, max_iter)\n",
    "lda_labels = [x.argmax() for x in lda_matrix]\n",
    "score(lda_matrix, marked_labels, lda_labels)\n",
    "print(\"lda lda: %s second\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.688\n",
      "Completeness: 0.714\n",
      "V-measure: 0.701\n",
      "Adjusted Rand-Index: 0.225\n",
      "Silhouette Coefficient: 0.045\n",
      "Cluster count: 109\n",
      "lsa: 1.0879974365234375 second\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lsa_matrix = lsa(tfidf_matrix, n_clusters, max_iter)\n",
    "lsa_labels = [x.argmax() for x in lsa_matrix]\n",
    "score(lsa_matrix, marked_labels, lsa_labels)\n",
    "print(\"lsa: %s second\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
