{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сравнение алгоритмов кластеризации по метрикам качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных для кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class News:\n",
    "    def __init__(self, id, date, title, content, url, siteType):\n",
    "        self.id = id\n",
    "        self.date = date\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.url = url\n",
    "        self.siteType = siteType\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str):\n",
    "        json_dict = json.loads(json_str)\n",
    "        return cls(**json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('/data/10k.test.normalized.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        news.append(News.from_json(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 2717122\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for n in news:\n",
    "    words.extend(n.content.split())\n",
    "counts = Counter(words)\n",
    "one_time = [k for k, v in dict(counts).items() if v == 1]\n",
    "print(\"total words: %s\" % (len(words) - len(one_time)))\n",
    "\n",
    "news_content = [x.content for x in news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(one_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка размеченной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marked_map = {} # (id, label)\n",
    "with open('/data/mark_news.csv', encoding=\"utf8\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    for row in spamreader:\n",
    "        marked_map[row[0]] = int(row[3])\n",
    "\n",
    "marked_news = []\n",
    "for n in news:\n",
    "    label = marked_map[n.id]\n",
    "    marked_news.append((n.id, label))\n",
    "    \n",
    "marked_labels = [label for n_id, label in marked_news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked_map['170bf9b9-d62d-437e-a75a-cac7b7c9f282']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zip_news(n,l):\n",
    "    return list(map(assign_label_to_news, zip(n, l)))\n",
    "\n",
    "def assign_label_to_news(tuplezz):\n",
    "    (nws, lbl) = tuplezz\n",
    "    nws.label = lbl.item()\n",
    "    return nws\n",
    "\n",
    "def filter_words(text):\n",
    "    words_list = text.split()\n",
    "    newWords = [x for x in words_list if len(x) > 3]\n",
    "    return \" \".join(newWords)\n",
    "\n",
    "def print_clusters(cluster_news, clustre_labels):\n",
    "    newsLabels = zip_news(cluster_news, clustre_labels)\n",
    "    newsLabels = sorted(newsLabels, key=lambda n: n.label)\n",
    "    for label, group in groupby(newsLabels, lambda n: n.label):\n",
    "        groupList = list(group)\n",
    "        print(\"Cluster: %s, count news: %s, titles:\" % (label, len(groupList)))\n",
    "        for gr in groupList:\n",
    "            print(\"\\t\" + gr.title)\n",
    "            \n",
    "def print_topics(components, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(components):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(content):\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True, tokenizer=lambda text: text.split(\" \"), stop_words=stopwords) # , ngram_range=(1, 3)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(content)\n",
    "    print(\"vocabulary size: %s\" % len(tfidf_vectorizer.vocabulary_))\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda(content, n, max_iter, n_jobs):\n",
    "    tf = CountVectorizer(stop_words=stopwords).fit_transform(content)\n",
    "    lda = LatentDirichletAllocation(n_topics=n, max_iter=max_iter, learning_method='online', learning_offset=50., n_jobs=n_jobs)\n",
    "    lda_matrix = lda.fit_transform(tf)\n",
    "    return lda_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dbscan(matrix, eps, samples):\n",
    "    db = DBSCAN(eps=eps, min_samples=samples).fit(matrix)\n",
    "    labels = db.labels_\n",
    "    print('count clusters: %d' % (len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)))\n",
    "    labels = db.labels_\n",
    "    print(\"-1: %s, 0: %s\" % (labels.tolist().count(-1), labels.tolist().count(0)))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans(matrix, n, n_jobs):\n",
    "    km = KMeans(n_clusters=n, n_jobs=n_jobs).fit(matrix)\n",
    "    labels = km.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(matrix, marked_labels, clustered_labels):\n",
    "    print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(marked_labels, clustered_labels))\n",
    "    print(\"Completeness: %0.3f\" % metrics.completeness_score(marked_labels, clustered_labels))\n",
    "    print(\"V-measure: %0.3f\" % metrics.v_measure_score(marked_labels, clustered_labels))\n",
    "    print(\"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(marked_labels, clustered_labels))\n",
    "    print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(matrix, clustered_labels, sample_size=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тест "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_clusters = 130 # Количество кластеров\n",
    "n_topics = 1000 # Количество топиков для LDA\n",
    "n_jobs = 1 # Количество потоков для кластеризации\n",
    "max_iter = 10 # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 43607\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tf_idf(news_content)\n",
    "lda = lda(news_content, n_topics, max_iter, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans tf-idf...\n",
      "Homogeneity: 0.744\n",
      "Completeness: 0.753\n",
      "V-measure: 0.749\n",
      "Adjusted Rand-Index: 0.355\n",
      "Silhouette Coefficient: 0.041\n",
      "kmeans tf-idf: 618.5275161266327 second\n",
      "\n",
      "kmeans lda...\n",
      "Homogeneity: 0.514\n",
      "Completeness: 0.502\n",
      "V-measure: 0.508\n",
      "Adjusted Rand-Index: 0.127\n",
      "Silhouette Coefficient: 0.176\n",
      "kmeans lda: 34.0408833026886 second\n"
     ]
    }
   ],
   "source": [
    "# KMeans tfidf\n",
    "print(\"kmeans tf-idf...\")\n",
    "start_time = time.time()\n",
    "kk_labels = kmeans(tfidf_matrix, n_clusters, n_jobs)\n",
    "score(tfidf_matrix, marked_labels, kk_labels)\n",
    "print(\"kmeans tf-idf: %s second\" % (time.time() - start_time))\n",
    "print(\"\")\n",
    "\n",
    "# KMeans lda\n",
    "print(\"kmeans lda...\")\n",
    "start_time = time.time()\n",
    "kk_labels = kmeans(lda, n_clusters, n_jobs)\n",
    "score(lda, marked_labels, kk_labels)\n",
    "print(\"kmeans lda: %s second\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps_tf_idf = 1\n",
    "eps_lda = 0.1\n",
    "sampels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbscan tf-idf...\n",
      "count clusters: 76\n",
      "-1: 7891, 0: 105\n",
      "Homogeneity: 0.223\n",
      "Completeness: 0.751\n",
      "V-measure: 0.344\n",
      "Adjusted Rand-Index: 0.009\n",
      "Silhouette Coefficient: 0.003\n",
      "dbscan tf-idf: 8.35751724243164 second\n",
      "\n",
      "dbscan lda...\n",
      "count clusters: 15\n",
      "-1: 5730, 0: 3546\n",
      "Homogeneity: 0.099\n",
      "Completeness: 0.465\n",
      "V-measure: 0.164\n",
      "Adjusted Rand-Index: 0.011\n",
      "Silhouette Coefficient: -0.362\n",
      "dbscan lda: 25.161997318267822 second\n"
     ]
    }
   ],
   "source": [
    "# DBScan tfidf\n",
    "print(\"dbscan tf-idf...\")\n",
    "start_time = time.time()\n",
    "kk_labels = dbscan(tfidf_matrix, eps_tf_idf, sampels)\n",
    "score(tfidf_matrix, marked_labels, kk_labels)\n",
    "print(\"dbscan tf-idf: %s second\" % (time.time() - start_time))\n",
    "print(\"\")\n",
    "\n",
    "# DBScan lda\n",
    "print(\"dbscan lda...\")\n",
    "start_time = time.time()\n",
    "kk_labels = dbscan(lda, eps_lda, sampels)\n",
    "score(lda, marked_labels, kk_labels)\n",
    "print(\"dbscan lda: %s second\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
