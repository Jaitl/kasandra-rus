{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class News:\n",
    "    def __init__(self, id, date, title, content, url, siteType):\n",
    "        self.id = id\n",
    "        self.date = date\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.url = url\n",
    "        self.siteType = siteType\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_str):\n",
    "        json_dict = json.loads(json_str)\n",
    "        return cls(**json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('/data/kasandra/year/all.normalized.json', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        news.append(News.from_json(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words: 47479434\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for n in news:\n",
    "    words.extend(n.content.split())\n",
    "counts = Counter(words)\n",
    "one_time = [k for k, v in dict(counts).items() if v == 1]\n",
    "print(\"total words: %s\" % (len(words) - len(one_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = set(one_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zip_news(n,l):\n",
    "    return list(map(assign_label_to_news, zip(n, l)))\n",
    "\n",
    "def assign_label_to_news(tuplezz):\n",
    "    (nws, lbl) = tuplezz\n",
    "    nws.label = lbl.item()\n",
    "    return nws\n",
    "\n",
    "def filter_words(text):\n",
    "    words_list = text.split()\n",
    "    newWords = [x for x in words_list if len(x) > 3]\n",
    "    return \" \".join(newWords)\n",
    "\n",
    "def print_clusters(cluster_news, clustre_labels):\n",
    "    newsLabels = zip_news(cluster_news, clustre_labels)\n",
    "    newsLabels = sorted(newsLabels, key=lambda n: n.label)\n",
    "    for label, group in groupby(newsLabels, lambda n: n.label):\n",
    "        groupList = list(group)\n",
    "        print(\"Cluster: %s, count news: %s, titles:\" % (label, len(groupList)))\n",
    "        for gr in groupList:\n",
    "            print(\"\\t\" + gr.title)\n",
    "            \n",
    "def print_topics(components, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(components):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Март 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mart_start = 1425157200000\n",
    "mart_end = 1427835600000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count mart news: 2684\n"
     ]
    }
   ],
   "source": [
    "mart_news = list(filter(lambda x: x.date > mart_start and x.date < mart_end, news))\n",
    "mart_content = [filter_words(x.content) for x in mart_news]\n",
    "print(\"count mart news: %s\" % len(mart_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 23656\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, tokenizer=lambda text: text.split(\" \"), stop_words=stopwords, max_df=3, min_df=1) # , ngram_range=(1, 3)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(mart_content)\n",
    "print(\"vocabulary size: %s\" % len(tfidf_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count clusters: 1\n",
      "-1: 478, 0: 2206\n"
     ]
    }
   ],
   "source": [
    "X = (tfidf_matrix * tfidf_matrix.T).A #cosine\n",
    "db = DBSCAN(eps=1.1, min_samples=10).fit(X)\n",
    "labels = db.labels_\n",
    "\n",
    "print('count clusters: %d' % (len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)))\n",
    "\n",
    "labels = db.labels_\n",
    "print(\"-1: %s, 0: %s\" % (labels.tolist().count(-1), labels.tolist().count(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_clusters(mart_news, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news_clusters = {}\n",
    "for i in range(0, len(labels)):\n",
    "    n = mart_news[i]\n",
    "    l = labels[i]\n",
    "    news_clusters[n.id] = int(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_file = '/data/kasandra/year/result/50_kmens.json'\n",
    "\n",
    "with open(cluster_file, encoding=\"utf8\", mode=\"w\") as f:\n",
    "    d_json = json.dumps(news_clusters, ensure_ascii=False)\n",
    "    f.write(d_json + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
